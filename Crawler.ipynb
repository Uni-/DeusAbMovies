{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# notice\n",
    "# <_1 1st, _2 2nd ,,, > : tuple\n",
    "# [ ... ] : list\n",
    "# { keytype, valtype } : dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import request\n",
    "import requests\n",
    "\n",
    "# import pattern\n",
    "from pattern import web\n",
    "from pattern.web import Element\n",
    "from pattern.web import plaintext\n",
    "\n",
    "# import regular expression\n",
    "import re\n",
    "\n",
    "# import json\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_page(url) :\n",
    "    r = requests.get(url)\n",
    "    \n",
    "    if r.status_code is not 200 :\n",
    "        return None\n",
    "    \n",
    "    return r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Movie Counts per Year\n",
    "\n",
    "Crawl 'http://movie.naver.com/movie/sdb/browsing/bmovie_open.nhn' to get movie list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_count_on_year() :\n",
    "    # result { str year, int count }\n",
    "    result = dict()\n",
    "    \n",
    "    # crawl $url_dir\n",
    "    url_dir = 'http://movie.naver.com/movie/sdb/browsing/bmovie_open.nhn'\n",
    "    page = get_page(url_dir)\n",
    "    \n",
    "    # find data\n",
    "    elem_root = Element(page)\n",
    "    \n",
    "    elem_old_content = elem_root('div[id=\"old_content\"]')\n",
    "    if len(elem_old_content) is not 1 :\n",
    "        return None\n",
    "    \n",
    "    elem_td = elem_old_content[0]('td')\n",
    "    if len(elem_td) is 0 :\n",
    "        return None\n",
    "    \n",
    "    # parse\n",
    "    td_list = map(lambda x : plaintext(x.content), elem_td)\n",
    "    \n",
    "    year_count_list = map(lambda x : re.split('\\W+' ,x)[0:2], td_list)\n",
    "    \n",
    "    # save at result   \n",
    "    for year_count in year_count_list :\n",
    "        result[year_count[0]] = int(year_count[1])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_counts = get_movie_count_on_year()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MetaData For Each Movie\n",
    "\n",
    "Crawl http://movie.naver.com/movie/sdb/browsing/bmovie.nhn?open=XXXX&page=XXXX to get pair of (movie name, movie code)\n",
    "\n",
    "movie code is used to search movie info at http://movie.naver.com/movie/bi/mi/detail.nhn?code=XXXX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# return [ <str name, str code> ]\n",
    "def get_movie_list_of_year_page(year, page) :\n",
    "    url_base = 'http://movie.naver.com/movie/sdb/browsing/bmovie.nhn?'\n",
    "    url_append = 'open=' + year + '&page=' + page\n",
    "    \n",
    "    # find data\n",
    "    page = get_page(url_base + url_append)\n",
    "    \n",
    "    elem_root = Element(page)\n",
    "    \n",
    "    elem_old_content = elem_root('div[id=\"old_content\"]')\n",
    "    if len(elem_old_content) is not 1 :\n",
    "        return []\n",
    "    \n",
    "    elem_li = elem_old_content[0]('ul[class=\"directory_list\"] > li')\n",
    "    if len(elem_li) is 0 :\n",
    "        return []\n",
    "    \n",
    "    elem_a = map(lambda x : x('a')[0], elem_li)\n",
    "    \n",
    "    # parse\n",
    "    hrefs = map(lambda x : x.attrs['href'], elem_a)\n",
    "    codes = map(lambda x : re.split('\\D+', x)[1] if len(re.split('\\D+',x )) is 2 else None, hrefs)\n",
    "    names = map(lambda x : x.content, elem_a)\n",
    "    \n",
    "    \n",
    "    # save to result\n",
    "    result = map(lambda x : (names[x], codes[x]), range(len(codes)))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def get_movie_list_of_year(year) :\n",
    "    page_count = movie_counts[year] / 20\n",
    "    if movie_counts[year] % 20 is not 0 :\n",
    "        page_count = page_count + 1\n",
    "    \n",
    "    list_per_page = map(lambda x : get_movie_list_of_year_page(year, str(x)), range(1, page_count + 1))\n",
    "    list_per_year = reduce(lambda a, b : a + b, list_per_page, [])\n",
    "    \n",
    "    \n",
    "    return list_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter\n",
    "movie_counts['1940'] = 0\n",
    "movie_counts['1950'] = 0\n",
    "movie_counts['1960'] = 0\n",
    "movie_counts['1970'] = 0\n",
    "movie_counts['1980'] = 0\n",
    "movie_counts['2017'] = 0\n",
    "\n",
    "# save to json\n",
    "for year in movie_counts :\n",
    "    if movie_counts[year] is not 0 :\n",
    "        tmp = get_movie_list_of_year(year)\n",
    "\n",
    "        data_file = open('movie_list_' + year + '.txt', 'w')\n",
    "        json.dump(tmp, data_file, ensure_ascii=True)\n",
    "        data_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_list_of_year(year) :\n",
    "    data_file = open('movie_list_' + year + '.txt', 'r')\n",
    "    data = json.load(data_file)\n",
    "    data_file.close()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load list from jsons\n",
    "years = ['2015', '2014', '2016', '2011', '2010', '2013', '2012', '1991', '1990', \n",
    "         '1993', '1992', '1995', '1994', '1997', '1996', '1999', '1998', '2002', \n",
    "         '2003', '2000', '2001', '2006', '2007', '2004', '2005', '2008', '2009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movie_list_of_year = dict()\n",
    "\n",
    "# TODO: iterate through years and load\n",
    "for year in years :\n",
    "    movie_list_of_year[year] = load_list_of_year(year)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MovieData\n",
    "data at http://movie.naver.com/movie/bi/mi/detail.nhn?code=XXXX and http://movie.naver.com/movie/bi/mi/point.nhn?code=XXXX\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# { str param, object obj }\n",
    "# param : \n",
    "#    name\n",
    "#    watcher_rating\n",
    "#    netizen_rating\n",
    "#    expert_rating\n",
    "#    step1 : genre, nation, runtime, open_date\n",
    "#    director\n",
    "#    actor\n",
    "def get_movie_info(code) :\n",
    "    # result { str param, object obj }\n",
    "    result = dict()\n",
    "    \n",
    "    url_base = 'http://movie.naver.com/movie/bi/mi/detail.nhn?code='\n",
    "    r = requests.get(url_base + str(code))\n",
    "    \n",
    "    elem_root = Element(r.text);\n",
    "    \n",
    "    elem_info_area = elem_root('div[class=\"mv_info_area\"]')\n",
    "    if len(elem_info_area) is not 1 :\n",
    "        return None\n",
    "    \n",
    "    # name\n",
    "    elem_movie_name = elem_info_area[0]('h3[class=\"h_movie\"] > a')\n",
    "    if len(elem_movie_name) is 0 :\n",
    "        return None\n",
    "    \n",
    "    result['name'] = plaintext(elem_movie_name[0].content)\n",
    "    \n",
    "    # rate\n",
    "    elem_rating_group = elem_info_area[0]('div[class=\"main_score\"]')\n",
    "    if len(elem_rating_group) is 1 :\n",
    "    \n",
    "        # watcher rate\n",
    "        elem_actual_rate = elem_rating_group[0]('a[id=\"actualPointPersentBasic\"] > div > em')\n",
    "        list_actual_rate = map(lambda x : plaintext(x.content), elem_actual_rate)\n",
    "        actual_rate = reduce(lambda a, b : a + b, list_actual_rate, '')\n",
    "    \n",
    "        result['watcher_rating'] = actual_rate\n",
    "\n",
    "        # netizen rate\n",
    "        elem_netizen_rate = elem_rating_group[0]('a[id=\"pointNetizenPersentBasic\"] > em')\n",
    "        list_netizen_rate = map(lambda x : plaintext(x.content), elem_netizen_rate)\n",
    "        netizen_rate = reduce(lambda a, b : a + b, list_netizen_rate, '')\n",
    "    \n",
    "        result['netizen_rate'] = netizen_rate\n",
    "\n",
    "        #expert rate\n",
    "        elem_expert_rate = elem_rating_group[0]('div[class=\"spc_score_area\"] > a > div > em')\n",
    "        list_expert_rate = map(lambda x : plaintext(x.content), elem_expert_rate)\n",
    "        expert_rate = reduce(lambda a, b : a + b, list_expert_rate, '')\n",
    "    \n",
    "        result['expert_rate'] = expert_rate\n",
    "    else :\n",
    "        result['watcher_rating'] = None\n",
    "        result['netizen_rate'] = None\n",
    "        result['expert_rate'] = None\n",
    "\n",
    "#TODO : Fix Code to Parse Easily    \n",
    "    # step1 : genre, nation, runtime, open_date\n",
    "    elem_steps = elem_info_area[0]('dd')\n",
    "    if len(elem_steps) is not 0 :\n",
    "        elem_spans = elem_steps[0]('p > span')\n",
    "        \n",
    "        span_list = list()\n",
    "        for elem_span in elem_spans :\n",
    "            span_list.append(elem_span.source)\n",
    "        result['step1'] = span_list\n",
    "    else :\n",
    "        result['step1'] = list()\n",
    "\n",
    "        \n",
    "    # actor\n",
    "    elem_actor_area = elem_root('div[class=\"made_people\"]')\n",
    "    if len(elem_actor_area) is not 1 :\n",
    "        result['actor'] = list()\n",
    "    else :\n",
    "        elem_people_list = elem_actor_area[0]('ul[class=\"lst_people\"] > li a[class=\"k_name\"]')\n",
    "        actor_list = map(lambda x : plaintext(x.content), elem_people_list)\n",
    "        result['actor'] = actor_list\n",
    "    \n",
    "    \n",
    "    # director\n",
    "    elem_director_area = elem_root('div[class=\"director\"]')\n",
    "    if len(elem_director_area) is not 1 :\n",
    "        result['director'] = list()\n",
    "    else :\n",
    "        elem_directors = elem_director_area[0]('div[class=\"dir_obj\"]  a[class=\"k_name\"]')\n",
    "        director_list = map(lambda x : plaintext(x.content), elem_directors)\n",
    "        result['director'] = director_list\n",
    "    \n",
    "    return result\n",
    "\n",
    "# { str param, object obj }\n",
    "# param : \n",
    "#    name : str\n",
    "#    watcher_rating : float\n",
    "#    netizen_rating : float\n",
    "#    expert_rating : float\n",
    "#    genre : [ int genre_num ]\n",
    "#    nation : [ str nation_code ]\n",
    "#    runtime : int minute\n",
    "#    open_date : datetime\n",
    "#    \n",
    "def parse_movie_info(info) :\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419\n"
     ]
    }
   ],
   "source": [
    "print len(movie_list_of_year['2015'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occured on crawling [u'\\uac15\\ud55c\\uac74 \\ub2f9\\uc2e0\\uc758 \\ud0a4\\uc2a4 - \\uccb4\\ucde8 (Bride of the farmhouse I want to meet you)', u'143320']\n",
      "year : 2015 count : 100 done\n",
      "error occured on crawling [u'\\uad74\\uc695 \\uc870\\uad50 - \\ubd88\\ud0c0\\ub294 \\uc720\\ubd80\\ub140 (Rape training)', u'143271']\n",
      "error occured on crawling [u'\\uadf8 \\uc785\\uc220\\uc5d0 \\uc0ac\\ub791\\uc744 (Love a heart)', u'143243']\n",
      "error occured on crawling [u'\\uadf8\\ub140\\uc758 \\uc74c\\ub780\\ud55c \\uaf43 (When a married woman invites a man)', u'143349']\n",
      "year : 2015 count : 200 done\n",
      "error occured on crawling [u'\\ub2e4\\ub77d\\ubc29\\uc758\\ube44\\ubc00\\ubb34\\uc0ad\\uc81c\\ud310 (SECRETS IN THE ATTIC)', u'135960']\n",
      "error occured on crawling [u'\\ub2ec\\ube5b\\uc139\\uc2a4\\uc815\\uc0ac-\\uae30\\ubaa8\\ub178 (The beauty in the moonlight)', u'144437']\n",
      "year : 2015 count : 300 done\n",
      "error occured on crawling [u'\\ub450 \\uc787 (Do It!)', u'37920']\n",
      "error occured on crawling [u'\\ub5a1\\uad6d\\uc5f4\\ucc28\\uc758\\ube44\\ubc00\\uc560 (ABDUCTION TRAIN)', u'135331']\n",
      "error occured on crawling [u'\\ub780\\uad50 - \\ub2e5\\uce58\\uace0 \\uc815\\uc0ac', u'142825']\n",
      "error occured on crawling [u'\\ub7ec\\ube0c\\ud638\\ud154\\ubb34\\uc0ad\\uc81c\\ud310 (MAD SULTRY SISTERS)', u'135969']\n",
      "year : 2015 count : 400 done\n",
      "year : 2015 count : 500 done\n",
      "error occured on crawling [u'\\uc0ac\\ub791\\uacfc \\uc131\\uc695\\uc758 \\ucc28\\uc774 (The case file of Greed wife/ Between love and sexual desire)', u'143229']\n",
      "error occured on crawling [u'\\uc0ac\\ub791\\ubc16\\uc5d4 \\ub09c \\ubab0\\ub77c (All you need is love)', u'133234']\n",
      "error occured on crawling [u'\\uc0ac\\uc545\\ud55c \\uc815\\uc0ac', u'137412']\n",
      "year : 2015 count : 600 done\n",
      "error occured on crawling [u'\\uc11c\\ub3c4\\uac00\\uc758 \\uc815\\uc0ac - \\ubab8\\uc5d0 \\uadf8\\ub9ac\\ub294 \\ubd93 (Her mother Ill her past)', u'143348']\n",
      "error occured on crawling [u'\\uc139\\uc2a4\\uc911\\ub3c5 - \\uc544\\uc90c\\ub9c8 \\uc790\\ub9e4', u'142824']\n",
      "year : 2015 count : 700 done\n",
      "error occured on crawling [u'\\uc2dc\\ud06c\\ub9bf \\uac00\\uba74 \\uc139\\uc2a4 (Danchiduma-no-Himitsu)', u'133167']\n",
      "error occured on crawling [u'\\uc2e0\\uc785 \\uc5ec\\ud615\\uc0ac\\uc758 \\uacfc\\uac10\\ud55c \\uc815\\uc0ac', u'139103']\n",
      "error occured on crawling [u\"\\uc2e0\\uc8fc\\ucfe0 \\uc5d0\\ub85c\\uc2a4 (Unlucky Woman's Blues)\", u'132990']\n",
      "error occured on crawling [u'\\uc2e4\\uc81c\\ub85c \\uc788\\uc5c8\\ub358 \\uc870\\uac74\\ub9cc\\ub0a8 (Authentic record married woman encounter experience)', u'143247']\n",
      "year : 2015 count : 800 done\n",
      "error occured on crawling [u'\\uc554\\uce90\\ub4e4\\uc758 \\uc815\\uc0ac - \\uc720\\ubd80\\ub140', u'142823']\n",
      "year : 2015 count : 900 done\n",
      "error occured on crawling [u'\\uc625\\ubcf4\\ub2e8-\\uc74c\\ud589\\ud569\\uad81\\ube44\\uc0ac (THE CARNAL SUTRA MAT)', u'135615']\n",
      "year : 2015 count : 1000 done\n",
      "error occured on crawling [u\"\\uc720\\ubd80\\ub140\\uc758 \\uc74c\\ub2f4\\ud328\\uc124-\\uc2e4\\ud654 (The housing complex wives are dancing / Big tits and buts' strip show)\", u'143246']\n",
      "error occured on crawling [u'\\uc74c\\ub780\\ud55c \\uaf43\\ub4e4\\uc758 \\uc815\\uc0ac   (God in love~the kojiki)', u'133164']\n",
      "error occured on crawling [u\"\\uc74c\\ud0d5\\ud55c \\uc5ec\\ub300\\uc0dd \\uae30\\uc219\\uc0ac (Girls' dormitory on target/ Secretly afternoon of nasty caretaker)\", u'143223']\n",
      "year : 2015 count : 1100 done\n",
      "error occured on crawling [u'\\uc804\\ucca0\\uc5d0\\uc11c \\ub9cc\\ub09c \\uc0ac\\ub791\\uc774\\uc57c\\uae30 (Jituroku Chikandensya)', u'143231']\n",
      "error occured on crawling [u\"\\ucda9\\uaca9! \\ubcc0\\ud0dc\\ucee4\\ud50c (Hoshi's long day)\", u'133225']\n",
      "year : 2015 count : 1200 done\n",
      "error occured on crawling [u'\\ud0c4\\ud2b8\\ub77c \\uc139\\uc2a4 \\ubb34\\uc0ad\\uc81c\\ud310 (TANTRA SEX)', u'135601']\n",
      "year : 2015 count : 1300 done\n",
      "error occured on crawling [u'\\ud658\\uc790\\uc758 \\uc695\\uc815\\ud480\\uae30 - \\uac04\\ud638\\uc0ac (Midnight consulting room special 3)', u'145438']\n",
      "year : 2015 count : 1400 done\n",
      "error occured on crawling [u'\\ud669\\uae08 \\uc721\\uccb4 - \\uc815\\uc0ac\\uc758 \\ub9db (Golden body)', u'143283']\n"
     ]
    }
   ],
   "source": [
    "error_list = list()\n",
    "\n",
    "for key in movie_list_of_year :\n",
    "    movie_info = dict()\n",
    "    cnt = 0\n",
    "    for movie_meta in movie_list_of_year[key] :\n",
    "        tmp = get_movie_info(movie_meta[1])\n",
    "        if tmp is None :\n",
    "            error_list.append(movie_meta)\n",
    "            print 'error occured on crawling ' + str(movie_meta)\n",
    "        else :\n",
    "            movie_info[movie_meta[1]] = tmp\n",
    "        cnt = cnt + 1\n",
    "        if cnt % 100 is 0 :\n",
    "            print \"year : \" + str(key) + \" count : \" + str(cnt) + \" done\"\n",
    "    \n",
    "    data_file = open('movie_info_' + key + '.txt', 'w')\n",
    "    json.dump(movie_info, data_file, ensure_ascii=True)\n",
    "    data_file.close()    \n",
    "    \n",
    "error_file = open('error_list.txt')\n",
    "json.dump(error_list, error_file, ensure_ascii=True)\n",
    "error_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/movie/sdb/browsing/bmovie.nhn?genre=15\n",
      "/movie/sdb/browsing/bmovie.nhn?genre=2\n",
      "/movie/sdb/browsing/bmovie.nhn?genre=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "u'<div><a href=\"/movie/sdb/browsing/bmovie.nhn?genre=15\">\\\\uc560\\\\ub2c8\\\\uba54\\\\uc774\\\\uc158</a><!-- N=a:ifo.genre -->, <a href=\"/movie/sdb/browsing/bmovie.nhn?genre=2\">\\\\ud310\\\\ud0c0\\\\uc9c0</a><!-- N=a:ifo.genre -->, <a href=\"/movie/sdb/browsing/bmovie.nhn?genre=1\">\\\\ub4dc\\\\ub77c\\\\ub9c8</a><!-- N=a:ifo.genre --></div>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpstr = '<div><a href=\\\"/movie/sdb/browsing/bmovie.nhn?genre=15\\\">\\uc560\\ub2c8\\uba54\\uc774\\uc158</a><!-- N=a:ifo.genre -->, <a href=\\\"/movie/sdb/browsing/bmovie.nhn?genre=2\\\">\\ud310\\ud0c0\\uc9c0</a><!-- N=a:ifo.genre -->, <a href=\\\"/movie/sdb/browsing/bmovie.nhn?genre=1\\\">\\ub4dc\\ub77c\\ub9c8</a><!-- N=a:ifo.genre --></div>'\n",
    "e = Element(tmpstr)\n",
    "for key in e('a') :\n",
    "    print key.attr['href']\n",
    "e.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
